# ======================== alphamind 模型相关参数 ==========================
# mode=train
# train_data_dir=/ntt/datasets
# output_dir=/ntt/alphamind
# tensorboard_dir=/tensorboard
# logging_ini = /opt/config/logging.ini          # 日志配置文件
# vocab_file = /opt/config/vocab.txt           # 词汇表

# =========================== 模型相关参数 =================================
network_name = text_cnn_lstm                # 网络的选取 可选值范围为: [text_cnn_lstm]
train_data_dir = ./datasets                 # 训练数据存放路径
output_dir = ./alphamind                    # 模型持久化的路径，默认为./model
tensorboard_dir = ./tensorboard             # 模型图保存路径
logging_ini = ./config/logging.ini          # 日志配置文件
vocab_file = ./config/vocab.txt             # 词汇表
model_ckpt_name = 'bilstm_textcnn.model.ckpt'         # 模型保存名
input_vocab_size = 9000                     # 词汇表的大小
mode = 1                                    # GPU 选择策略
batch_size = 32                             # 批次大小
num_epochs = 50                             # 训练批次
ckpt_model_num = 200                        # 多少步时候持久化模型一次
steps_per_checkpoint = 10                   # 多少步时候持打损失 准确率
embedding_size = 128                        # embedding输出的维度
num_calss = 2                               # 分类的label的数量
max_seq_length = 2000                        # 每个批次最大长度
dropout_rate = 0.5                          # 丢弃概率
rnn_size = 128